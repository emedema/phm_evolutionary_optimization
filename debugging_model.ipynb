{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "438b361b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import transformers\n",
    "from transformers import AutoModel, BertTokenizerFast\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import AdamW\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bba395cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text     object\n",
      "label     int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "## load in the dataset\n",
    "col1_names=['id', 'tweet_id', 'text', 'username']\n",
    "col2_names = ['tweet_id', 'disease', 'label']\n",
    "df1 = pd.read_csv(\"tweets/phm2017_tweets.csv\", names=col1_names, header=None)\n",
    "df2 = pd.read_csv(\"new_data/PHM2017.csv\", names=col2_names, header=None)\n",
    "df = pd.merge(df1, df2, on=\"tweet_id\")\n",
    "df = df.drop(['id', 'tweet_id', 'username', 'disease'], axis=1)\n",
    "df['label'] = df['label'].astype(int)\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5175006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New Alzheimer Society resources to support a m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What to Know About Thyroid and Alzheimer's htt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hippocampus ! If this part are damage we could...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How tackling hearing loss could reduce your ri...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Finding the fun in the fog of Alzheimer’s\\nvia...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  New Alzheimer Society resources to support a m...      1\n",
       "1  What to Know About Thyroid and Alzheimer's htt...      1\n",
       "2  Hippocampus ! If this part are damage we could...      1\n",
       "3  How tackling hearing loss could reduce your ri...      1\n",
       "4  Finding the fun in the fog of Alzheimer’s\\nvia...      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7ee699c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4416, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape = df.shape\n",
    "shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22979d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train test split\n",
    "train_text, temp_text, train_labels, temp_labels = train_test_split(df['text'], df['label'],\n",
    "                                                                    random_state=2018,\n",
    "                                                                    test_size=0.3,\n",
    "                                                                    stratify=df['label'])\n",
    "\n",
    "# we will use temp_text and temp_labels to create validation and test set\n",
    "val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels,\n",
    "                                                                random_state=2018,\n",
    "                                                                test_size=0.5,\n",
    "                                                                stratify=temp_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfda4761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3091,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "270fd176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1325,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "570c87de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f13468d5aca042bd9c82a5e666d22901",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0549b9d3da2f4d0a95cdffeca1a07e80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6adc32b9b1974b948bbaa8138045fa22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4314f9c50e14b18a38f04bf79c56c28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9694e22976ce4e64bc85f4ba87bbd8a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import BERT-base pretrained model\n",
    "bert = AutoModel.from_pretrained('bert-base-uncased', return_dict=False)\n",
    "\n",
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "465c5bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3091, 280])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "############### TOKENIZATION ###############\n",
    "# get length of all the messages in the train set\n",
    "seq_len = [len(i.split()) for i in train_text]\n",
    "\n",
    "pd.Series(seq_len).hist(bins = 30)\n",
    "\n",
    "max_seq_len = 280 ## change this maybe?\n",
    "\n",
    "def tokenize_text(df, max_seq):\n",
    "    return [\n",
    "        tokenizer.encode(text, add_special_tokens=True)[:max_seq] for text in df\n",
    "    ]\n",
    "\n",
    "\n",
    "def pad_text(tokenized_text, max_seq):\n",
    "    return np.array([el + [0] * (max_seq - len(el)) for el in tokenized_text])\n",
    "\n",
    "\n",
    "def tokenize_and_pad_text(df, max_seq):\n",
    "    tokenized_text = tokenize_text(df, max_seq)\n",
    "    padded_text = pad_text(tokenized_text, max_seq)\n",
    "    return torch.tensor(padded_text)\n",
    "\n",
    "\n",
    "def targets_to_tensor(df, target_columns):\n",
    "    return torch.tensor(df[target_columns].values, dtype=torch.float32)\n",
    "\n",
    "\n",
    "train_indices = tokenize_and_pad_text(train_text, max_seq_len)\n",
    "val_indices = tokenize_and_pad_text(val_text, max_seq_len)\n",
    "test_indices = tokenize_and_pad_text(test_text, max_seq_len)\n",
    "\n",
    "print(train_indices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8642cc6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  101,  1018,  3928,  5878,  2055, 20310,  1005,  1055,  1998,  3652,\n",
       "         3080,  1064,  5863,  5253,  1064,  6945,  7566, 16770,  1024,  1013,\n",
       "         1013,  1056,  1012,  2522,  1013, 11937,  2278,  2615, 26876,  2480,\n",
       "         2361,  2615,  2629, 16770,  1024,  1013,  1013,  1056,  1012,  2522,\n",
       "         1013,  8740,  8889, 18927,  2361,  2615,  2721,   102,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_indices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d263714c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    x_train = bert(train_indices)[0]  # Models outputs are tuples\n",
    "    print(\"Got past x_train\")\n",
    "    x_val = bert(val_indices)[0]\n",
    "    print(\"Got past x_val\")\n",
    "    x_test = bert(test_indices)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c5925a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = torch.tensor(train_labels.tolist())\n",
    "y_val = torch.tensor(val_labels.tolist())\n",
    "y_test = torch.tensor(test_labels.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ba57c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780dcd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12da3e45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
